# Avoiding Uniformity and Plagiarism 

**Context:** A quick reference for students and researchers worried that heavy use of large‑language models might make everyone’s writing look the same and trigger plagiarism concerns.


## Why the “AI‑tongue” Feels Uniform

* LLMs compress patterns from vast text corpora; their *first‑pass* drafts (especially with simple prompts) inherit common phrasing and structure.  
* [Messeri & Crockett (2024)](https://doi.org/10.1038/s41586-024-07146-0) describe this risk as a **scientific monoculture**—high output, lower diversity.


## Work *With* the Model, Not *For* It (“Interaction Fluents”)

1. **Seed** the model with your rough notes or `{key ideas in braces}`.  
2. **Probe** with follow‑up *“why / evidence?”* questions.  
3. **Layer** your own analysis and writing on top.  
4. **Iterate** until the text sounds like **you**, not the system. Think of yourself as the composer: organising/arranging, integrating and pulling it all together.

See the [Anthropic Education Report](https://www.anthropic.com/news/anthropic-education-report-how-university-students-use-claude) for student examples of Claude being used this way.


## Guard‑Rails Against Plagiarism & Echoing

| Step | Practice | Why it Matters |
|------|----------|----------------|
| 1 | **Run final drafts through a plagiarism checker** (Turnitin, iThenticate, etc.) | Detects inadvertent overlap. |
| 2 | **Maintain manual literature searches** (Google Scholar, Scopus, Web of Science, library databases) | Ensures coverage & reduces echo‑chamber risk. |
| 3 | **Parallel AI‑assisted discovery** with tools such as Perplexity, Elicit, Scholar AI | Surfaces additional keywords & perspectives. |
| 4 | **Iteratively refine search phrases** across *both* manual and AI searches | Expands and diversifies the knowledge base. |
| 5 | **Disclose substantive AI assistance** in Methods/Acknowledgements | Meets journal transparency guidelines. |


## Real‑Time Case Study: [Sycophancy in GPT-4o](https://openai.com/index/sycophancy-in-gpt-4o/)

OpenAI rolled back a recent *GPT‑4o* update after users flagged disingenuous flattery (*sycophancy*).  
*Take‑away:* User prompts, critiques and feedback mechanisms (short-term, long-term) actively **co‑evolve** model behaviour and it's knowledge base—another reason to stay critically engaged rather than copy‑paste outputs.


## The Pay‑Off

Used as an *iterative collaborator*, LLMs can:

* Speed up idea generation and coding support/debugging.  
* Offer an argumentation partner for critiquing your work and ideas.  
* **Widen**—rather than narrow—your knowledge base while you remain responsible for originality and rigour.


## Recording & Further Resources

Follow the **ARC BITA Centre** LinkedIn page for the workshop recording once uploaded.  
* LinkedIn: <https://www.linkedin.com/company/arc-ittc-bita/>
* YouTube: <https://www.youtube.com/@ARCBITA>

The workshop recording is also available via the YouTube channel for UWA's School of Agriculture and Environment: <https://www.youtube.com/user/AREatUWA/>.
